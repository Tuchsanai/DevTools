
# ğŸš€ Load Balancer with Nginx + Docker

This lab shows how to use **Nginx** as a **load balancer** for multiple **Express.js containers**.

Think of a load balancer like a **traffic police officer at an intersection** ğŸš¦. When cars (requests) come in, the officer decides **which road (server)** each car should go to. This helps prevent one road from being too crowded.

We will learn 2 main strategies:

* **ğŸ”„ Round Robin** â†’ Requests are passed one by one to each server in order.
* **âš–ï¸ Weighted Round Robin** â†’ Some servers get more requests than others (based on assigned weight).

---

## ğŸ“Œ Load Balancing Concepts

### ğŸ”„ Round Robin

**How it works:**
Imagine you have 3 cashiers in a supermarket. Each new customer is sent to the next cashier in line. This ensures everyone gets work evenly.

![Round Robin](round.png)

**nginx.conf example:**

```nginx
events {}

http {
  upstream food-app {
    server food-server1:5000;
    server food-server2:3000;  
    server food-server3:8000;  
  }

  server {
    listen 80;

    location / {
      proxy_pass http://food-app;
    }
  }
}
```

â¡ï¸ In this setup, Nginx will forward requests **one by one**:
First to `food-server1`, then `food-server2`, then `food-server3`, and repeat.

---

### âš–ï¸ Weighted Round Robin

**How it works:**
Now imagine one cashier works faster than the others. You want that cashier to handle **more customers**.

Thatâ€™s what weights do. If cashier A has weight **3** and cashier B has weight **2**, cashier A will get 3 customers for every 2 customers that go to cashier B.

![Weighted Round Robin](weight.png)

**nginx.conf example:**

```nginx
# Example weight 3:2
events {}

http {
  upstream food-app {
    server food-server1:5000 weight=3;
    server food-server2:3000 weight=2;  
  }

  server {
    listen 80;

    location / {
      proxy_pass http://food-app;
    }
  }
}
```

â¡ï¸ This means:

* `food-server1` gets **3 requests**
* `food-server2` gets **2 requests**
* Then the cycle repeats.

---

## ğŸ§ª LAB A: Round Robin

We will build and run 2 Express servers, then use Nginx to balance requests between them.

---

### 1ï¸âƒ£ Create a Project Folder

```bash
mkdir LAB1_Week10
cd LAB1_Week10
```

ğŸ‘‰ Why?
We create a clean workspace to avoid mixing files with other projects.

---

### 2ï¸âƒ£ Clone the Repository

```bash
git clone -b dev https://github.com/Tuchsanai/DevTools.git
cd DevTools/02_Docker/Week10/01_LAB1_Nginx_LoadBalance
```

ğŸ‘‰ Why?
This repo already has a simple Express app that returns a message.
Weâ€™ll run multiple copies of it.

---

### 3ï¸âƒ£ Build the Express App Image

```bash
docker build -t express-app .
```

ğŸ‘‰ Why?
This creates a Docker image called **express-app** from the code inside the repo.
Think of it as a **template** you can use to create many containers.

---

### 4ï¸âƒ£ Create a Docker Network

```bash
docker network create express-network
```

ğŸ‘‰ Why?
Containers need a **shared network** so Nginx can talk to the Express apps by name (`app1`, `app2`).

---

### 5ï¸âƒ£ Run Two Express Containers

```bash
docker run -d --name app1 --network express-network -p 3001:3000 express-app
docker run -d --name app2 --network express-network -p 3002:3000 express-app
```

ğŸ‘‰ Why?
We now have 2 running apps (`app1` and `app2`). Each one responds differently (so we can tell them apart).

Check containers:

```bash
docker ps -a
```

---

### 6ï¸âƒ£ Configure & Run Nginx Load Balancer

Create `nginx.conf`:

```nginx
events {}

http {
    upstream backend {
        server app1:3000;
        server app2:3000;
    }

    server {
        listen 8080;

        location / {
            proxy_pass http://backend;
        }
    }
}
```

ğŸ‘‰ Explanation:

* **upstream backend** â†’ Defines the group of servers (`app1` and `app2`).
* **listen 8080** â†’ Nginx listens on port 8080.
* **proxy\_pass** â†’ Forwards requests to `backend`.

Run Nginx container:

```bash
docker run -d --name nginx-load-balancer \
  --network express-network \
  -p 8080:8080 \
  -v ./nginx.conf:/etc/nginx/nginx.conf:ro \
  nginx
```

Check container:

```bash
docker ps -a
```

---

### 7ï¸âƒ£ Test Load Balancing

Open in browser:

```
http://ExternalIP:8080
```

Refresh the page multiple times. You should see responses switching between `app1` and `app2`.

| From App1      | From App2      |
| -------------- | -------------- |
| ![App1](1.jpg) | ![App2](2.jpg) |

---

## ğŸ§ª LAB B: Weighted Round Robin

ğŸ‘‰ Try modifying `nginx.conf` so that one app receives **more traffic** than the other.



---

## ğŸ§¹ Cleanup

When youâ€™re done, stop and remove everything:

```bash
docker stop $(docker ps -a -q)  
docker rm $(docker ps -a -q) 
docker rmi $(docker images -q) 
docker volume rm $(docker volume ls -q)  
docker network prune -f
```

